{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizador de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para otimizar nas analises de textos, pegar um texto e limpar e um otimo processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpar tags html do texto se tiver\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover palavraas com acento\n",
    "def remove_accent(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode(\n",
    "        'ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover caracter especial\n",
    "def remove_special_char(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_text = ' '.join(\n",
    "        [token for token in tokens if token.lower() not in stopword_list])\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizator(text):\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    #remove html\n",
    "    text = strip_html_tags(text)\n",
    "\n",
    "    # remove 'stopword'\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    #remove acento\n",
    "    text = remove_accent(text)\n",
    "\n",
    "    #remove new line extra\n",
    "    text = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', text)\n",
    "\n",
    "    #inserir espaco entre caracter especial\n",
    "    special_char_pattern = re.compile(r'[\\}\\}\\\\\\(\\)\\./!-]')\n",
    "    text = special_char_pattern.sub(\" \", text)\n",
    "\n",
    "    #remove caracter especial\n",
    "    text = remove_special_char(text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf, Word2Vec e FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns exemplos de como se comportam os 3 algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf():\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(vocab):\n",
    "    # Criacao do modelo\n",
    "    model = Word2Vec(vocab, size=200,window=10,min_count=2,workers=10, sample=0)\n",
    "    # Treinamento do modelo\n",
    "    model.train(vocab, total_examples=model.corpus_count, epochs=100)\n",
    "    \n",
    "    model.save('model_wv.model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext(vocab):\n",
    "    # Criacao do modelo\n",
    "    model = FastText(size=200,window=10,min_count=2,workers=10, negative=5, min_n=3, max_n=5, sample=1e-5)\n",
    "    # Criar vocabulario\n",
    "    model.build_vocab(vocab)\n",
    "    # Treinamento do moedelo\n",
    "    model.train(vocab,total_examples=model.corpus_count, epochs=100)\n",
    "    \n",
    "    model.save('model_ft.model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(setences):\n",
    "    \n",
    "    setences = [normalizator(setence) for setence in setences] \n",
    "    \n",
    "    splited_setence = list()\n",
    "    \n",
    "    # Tokenizar palavras para o word2vec e o fasttext\n",
    "    for setence in setences:\n",
    "        splited_setence.append(setence.split())\n",
    "      \n",
    "    # Instancia modelos\n",
    "    model_tfidf = tfidf()\n",
    "    model_wv = word2vec(splited_setence)\n",
    "    model_ft = fasttext(splited_setence)\n",
    "    \n",
    "    return model_tfidf,model_wv, model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-885ea923475d>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-885ea923475d>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def initialize_models():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instancia do DataSet para teste e criacao dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Astronomia é uma ciência natural que estuda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ela está preocupada com a evolução , a física ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A astronomia é uma das mais antigas ciências .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Culturas pré - históricas deixaram registrados...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As primeiras civilizações , como os babilônios...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              frases\n",
       "0  A Astronomia é uma ciência natural que estuda ...\n",
       "1  Ela está preocupada com a evolução , a física ...\n",
       "2     A astronomia é uma das mais antigas ciências .\n",
       "3  Culturas pré - históricas deixaram registrados...\n",
       "4  As primeiras civilizações , como os babilônios..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/gabriel/Documents/Datasets/wikipedia.txt', delimiter='\\t')\n",
    "df.columns = ['frases']\n",
    "setences = [setence for setence in df['frases'][:10000]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.860086e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.232191e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.337409e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.070000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.640000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.512000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "count  7.860086e+06\n",
       "mean   1.232191e+02\n",
       "std    1.337409e+02\n",
       "min    1.000000e+00\n",
       "25%    6.300000e+01\n",
       "50%    1.070000e+02\n",
       "75%    1.640000e+02\n",
       "max    7.512000e+04"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamanho dos texto\n",
    "\n",
    "lengths = [len(setence) for setence in df['frases']]\n",
    "lengths = pd.DataFrame(lengths, columns=[\"count\"])\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=13482, size=200, alpha=0.025) \n",
      " FastText(vocab=13482, size=200, alpha=0.025) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_tfidf ,model_wv, model_ft = create_models(setences)\n",
    "print(model_wv, '\\n', model_ft, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Similaridade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste com os algoritmos para ver o desempenho dependendo da frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media dos vetores do FastText e Word2Vec\n",
    "def avg_feature_vector(sentence, model, num_features, index2word_set, fasttext=True):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    \n",
    "    if fasttext == True:\n",
    "        for word in words:\n",
    "            if word in index2word_set:\n",
    "                n_words += 1\n",
    "                feature_vec = np.add(feature_vec, model[word])\n",
    "            else:\n",
    "                try:\n",
    "                    word = model.most_similar(word)[0][0]\n",
    "                    n_words += 1\n",
    "                    feature_vec = np.add(feature_vec, model[word])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    else:\n",
    "        for word in words:\n",
    "            if word in index2word_set:\n",
    "                n_words += 1\n",
    "                feature_vec = np.add(feature_vec, model[word])                 \n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de similaridade entre duas frases Word2Vec e FastText\n",
    "def similarity(setence1, setence2, model, index2word_set, isfasttext=True):\n",
    "    s1_avg = avg_feature_vector(normalizator(setence1), model=model, num_features=200, index2word_set=index2word_set, fasttext=isfasttext)\n",
    "    s2_avg = avg_feature_vector(normalizator(setence2), model=model, num_features=200, index2word_set=index2word_set, fasttext=isfasttext)\n",
    "    percent = cosine_similarity([s1_avg], [s2_avg])[0][0]\n",
    "    return \"{0:.2}\".format(percent) + ' %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similaridade com Word2Vec e FastText\n",
    "def test_similarity(setence1, setence2):\n",
    "    \n",
    "    print(\"---------- Similarity ----------\\n\")\n",
    "    print('Setence 1 =',setence1,' \\nSetence 2 =',setence2, '\\n')\n",
    "    \n",
    "    # Similaridade TfIfd\n",
    "    tfidf_sim = model_tfidf.fit_transform([normalizator(setence1),normalizator(setence2)])\n",
    "    print(\"TfIdf\\t\\t-> \\t\",  '{0:.2}'.format(((tfidf_sim * tfidf_sim.T).A)[0,1]) + ' %')\n",
    "    \n",
    "    # Similaridade Word2Vec\n",
    "    index2word_set_wv = model_wv.wv.vocab\n",
    "    wv_sim = similarity(setence1, setence2, model_wv, index2word_set_wv, isfasttext=False)\n",
    "    print(\"Word2Vec\\t-> \\t\", wv_sim)\n",
    "    \n",
    "    \n",
    "    # Similaridade FastText\n",
    "    index2word_set_ft = model_ft.wv.vocab\n",
    "    ft_sim = similarity(setence1, setence2, model_ft, index2word_set_ft,isfasttext=True)\n",
    "    print(\"FastText\\t-> \\t\", ft_sim) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Similarity ----------\n",
      "\n",
      "Setence 1 = queria saber como abro uma conta universitaria  \n",
      "Setence 2 = queria ver o saldo da minha conta! \n",
      "\n",
      "TfIdf\t\t-> \t 0.29 %\n",
      "Word2Vec\t-> \t 0.6 %\n",
      "FastText\t-> \t 0.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/gabriel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "test_similarity(\"queria saber como abro uma conta universitaria\" , \"queria ver o saldo da minha conta!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
