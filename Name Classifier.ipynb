{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicode2ascii(name):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', name)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_names = dict()\n",
    "for path in glob.glob('data/names/*.txt'):\n",
    "    names = open(path).read().strip().split()\n",
    "    names = [unicode2ascii(name) for name in names]\n",
    "    langs_names[os.path.basename(path).strip('.txt')] = names\n",
    "    \n",
    "n_langs = len(langs_names)\n",
    "all_langs = list(langs_names.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter2tensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][all_letters.find(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name),1, n_letters)\n",
    "    for i, letter in enumerate(name):\n",
    "        tensor[i][0][all_letters.find(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_train_examples():\n",
    "    lang = random.choice(all_langs)\n",
    "    name = random.choice(langs_names[lang])\n",
    "    return lang, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lang_tensor, name_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(name_tensor.size(0)):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "    \n",
    "    loss = criterion(output, lang_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "        \n",
    "    return output, loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 iter\n",
      "10000 iter\n",
      "15000 iter\n",
      "20000 iter\n",
      "25000 iter\n",
      "30000 iter\n",
      "35000 iter\n",
      "40000 iter\n",
      "45000 iter\n",
      "50000 iter\n",
      "55000 iter\n",
      "60000 iter\n",
      "65000 iter\n",
      "70000 iter\n",
      "75000 iter\n",
      "80000 iter\n",
      "85000 iter\n",
      "90000 iter\n",
      "95000 iter\n",
      "100000 iter\n"
     ]
    }
   ],
   "source": [
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "\n",
    "rnn = RNN(n_letters,256, n_langs)\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    lang, name = random_train_examples()\n",
    "    lang_tensor = torch.tensor([all_langs.index(lang)], dtype=torch.long)\n",
    "    name_tensor = name2tensor(name)\n",
    "    output, loss = train(lang_tensor, name_tensor)\n",
    "    \n",
    "    if iter % print_every == 0:\n",
    "        print('%d iter' % iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(name_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "\n",
    "    for i in range(name_tensor.size()[0]):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.41"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(10000):\n",
    "    lang, name = random_train_examples()\n",
    "    lang_tensor = torch.tensor([all_langs.index(lang)], dtype=torch.long)\n",
    "    name_tensor = name2tensor(name)\n",
    "    output = evaluate(name_tensor)\n",
    "    topv, topi = output.topk(1,1,True)\n",
    "    lang_i = topi[0].item()\n",
    "    if lang_i == all_langs.index(lang):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "\n",
    "correct*100/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_name, n_predictions=3):\n",
    "    print('\\n> %s' % input_name)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(name2tensor(input_name))\n",
    "        \n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            lang_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_langs[lang_index]))\n",
    "            predictions.append([value, all_langs[lang_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Satoshi\n",
      "(-1.43) Arabic\n",
      "(-1.51) Japanese\n",
      "(-2.04) Polish\n"
     ]
    }
   ],
   "source": [
    "predict('Satoshi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
