{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 \n",
    "\n",
    "def unicode_to_ascii(name):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', name)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_names = dict()\n",
    "\n",
    "for filename in glob.glob('data/names/*.txt'):\n",
    "    lang = os.path.basename(filename).strip('.txt')\n",
    "    names = open(filename).read().strip().split('\\n')\n",
    "    names = [unicode_to_ascii(name) for name in names]\n",
    "    lang_names[lang] = names\n",
    "    \n",
    "all_langs = list(lang_names.keys())\n",
    "n_langs = len(all_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(n_langs + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_langs + input_size + hidden_size, output_size)\n",
    "        \n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0,1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, lang, input, hidden):\n",
    "        input_combined = torch.cat((lang, input, hidden), 1)\n",
    "        \n",
    "        hidden = self.i2h(input_combined)\n",
    "        \n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output),1)\n",
    "        \n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot tensors\n",
    "\n",
    "def make_lang_tensor(lang):\n",
    "    i = all_langs.index(lang)\n",
    "    tensor = torch.zeros(1,n_langs)\n",
    "    tensor[0][i] = 1\n",
    "    return tensor\n",
    "    \n",
    "def make_input_tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for i in range(len(name)):\n",
    "        letter = name[i]\n",
    "        tensor[i][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def make_target_tensor(name):\n",
    "    letter_indexes = [all_letters.find(name[i]) for i in range(1, len(name))]\n",
    "    letter_indexes.append(n_letters - 1)\n",
    "    return torch.LongTensor(letter_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training():\n",
    "    random_lang = random.choice(all_langs)\n",
    "    random_name = random.choice(lang_names[random_lang])\n",
    "    \n",
    "    lang_tensor = make_lang_tensor(random_lang)\n",
    "    input_tensor = make_input_tensor(random_name)\n",
    "    target_tensor = make_target_tensor(random_name)\n",
    "    \n",
    "    return lang_tensor, input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(lang_tensor, input_tensor, target_tensor):\n",
    "    \n",
    "    target_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(input_tensor.size(0)):\n",
    "        output, hidden = rnn(lang_tensor, input_tensor[i], hidden)\n",
    "        l = criterion(output, target_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "    return output, loss.item() / input_tensor.size(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 9s (5000 5%) 2.5079\n",
      "0m 19s (10000 10%) 2.4134\n",
      "0m 28s (15000 15%) 2.3434\n",
      "0m 37s (20000 20%) 1.8466\n",
      "0m 46s (25000 25%) 2.1607\n",
      "0m 55s (30000 30%) 2.1970\n",
      "1m 5s (35000 35%) 2.7081\n",
      "1m 16s (40000 40%) 2.4509\n",
      "1m 26s (45000 45%) 2.8063\n",
      "1m 35s (50000 50%) 3.3423\n",
      "1m 45s (55000 55%) 2.0338\n",
      "1m 54s (60000 60%) 2.7576\n",
      "2m 4s (65000 65%) 3.1084\n",
      "2m 13s (70000 70%) 2.4004\n",
      "2m 23s (75000 75%) 2.4036\n",
      "2m 34s (80000 80%) 2.2284\n",
      "2m 44s (85000 85%) 1.2419\n",
      "2m 53s (90000 90%) 2.0227\n",
      "3m 3s (95000 95%) 2.2170\n",
      "3m 13s (100000 100%) 2.2876\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*random_training())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(lang, start_letter='A'):\n",
    "    with torch.no_grad():\n",
    "        lang_tensor = make_lang_tensor(lang)\n",
    "        input_tensor = make_input_tensor(start_letter)\n",
    "        hidden = rnn.init_hidden()\n",
    "        \n",
    "        output_name = start_letter\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(lang_tensor, input_tensor[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            \n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            \n",
    "            input_tensor = make_input_tensor(letter)\n",
    "        \n",
    "        return output_name\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gangan'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample('Irish', 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Portuguese', 'English', 'French', 'Korean', 'Vietnamese', 'Russian', 'Arabic', 'Dutch', 'Japanese', 'Scottish', 'Chinese', 'Greek', 'Spanish', 'Italian', 'German', 'Irish', 'Czech', 'Polish']\n"
     ]
    }
   ],
   "source": [
    "print(all_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
